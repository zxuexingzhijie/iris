# 鸢尾花数据集分类实验

## 实验目的

本实验旨在对鸢尾花（Iris）数据集应用多种机器学习分类算法，比较不同算法的性能，并选择最优算法进行详细分析。通过本实验，我们将探索：

1. 不同分类算法的工作原理和适用场景
2. 模型评估指标的计算与解读
3. 交叉验证的实现与作用
4. 分类结果的可视化与解释

## 数据集介绍

鸢尾花数据集是机器学习领域最著名的数据集之一，包含了150个样本，每个样本有4个特征：

- 花萼长度（sepal length）
- 花萼宽度（sepal width）
- 花瓣长度（petal length）
- 花瓣宽度（petal width）

数据集中的样本属于三种不同的鸢尾花品种：

- Iris-setosa（山鸢尾）
- Iris-versicolor（变色鸢尾）
- Iris-virginica（维吉尼亚鸢尾）

每个品种各有50个样本。

## 文件结构

```
lab2/
├── data/                        # 预处理后的数据文件
│   ├── iris_processed.csv       # 处理后的原始数据
│   ├── X_train_scaled.npy       # 标准化后的训练特征
│   ├── X_test_scaled.npy        # 标准化后的测试特征
│   ├── y_train.npy              # 训练标签
│   ├── y_test.npy               # 测试标签
│   ├── scaler.joblib            # 特征标准化模型
│   └── label_encoder.joblib     # 标签编码器
└── iris_classification.py       # 分类实验主代码
```

## 实验方法

本实验实现了多种分类算法并进行了比较分析：

1. **逻辑回归 (Logistic Regression)** - 基于概率的线性分类方法
2. **支持向量机 (SVM)** - 寻找最佳分割超平面的方法
3. **决策树 (Decision Tree)** - 基于规则的分类方法
4. **随机森林 (Random Forest)** - 集成多个决策树的方法
5. **K近邻 (K-Nearest Neighbors)** - 基于距离的分类方法

### 各算法的关键实现代码

下面展示了每种算法的关键实现代码：

#### 1. 逻辑回归 (Logistic Regression)

```python
from sklearn.linear_model import LogisticRegression

# 创建逻辑回归模型
lr_model = LogisticRegression(max_iter=1000, random_state=42)

# 训练模型
lr_model.fit(X_train, y_train)

# 预测
y_pred = lr_model.predict(X_test)

# 预测概率（用于ROC曲线）
y_prob = lr_model.predict_proba(X_test)
```

#### 2. 支持向量机 (SVM)

```python
from sklearn.svm import SVC

# 创建SVM模型，使用径向基核函数
svm_model = SVC(probability=True, random_state=42)

# 训练模型
svm_model.fit(X_train, y_train)

# 预测
y_pred = svm_model.predict(X_test)

# 预测概率
y_prob = svm_model.predict_proba(X_test)
```

#### 3. 决策树 (Decision Tree)

```python
from sklearn.tree import DecisionTreeClassifier

# 创建决策树模型
dt_model = DecisionTreeClassifier(random_state=42)

# 训练模型
dt_model.fit(X_train, y_train)

# 预测
y_pred = dt_model.predict(X_test)
```

#### 4. 随机森林 (Random Forest)

```python
from sklearn.ensemble import RandomForestClassifier

# 创建随机森林模型
rf_model = RandomForestClassifier(random_state=42)

# 训练模型
rf_model.fit(X_train, y_train)

# 预测
y_pred = rf_model.predict(X_test)
```

#### 5. K近邻 (K-Nearest Neighbors)

```python
from sklearn.neighbors import KNeighborsClassifier

# 创建K近邻模型，默认k=5
knn_model = KNeighborsClassifier()

# 训练模型
knn_model.fit(X_train, y_train)

# 预测
y_pred = knn_model.predict(X_test)
```

### 交叉验证实现

本实验使用了`cross_validate`函数执行5折交叉验证，关键代码如下：

```python
from sklearn.model_selection import cross_validate, KFold

# 设定KFold交叉验证
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# 定义评估指标
scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc_ovr']

# 执行交叉验证
cv_result = cross_validate(
    classifier, X, y, 
    cv=kfold, 
    scoring=scoring, 
    return_train_score=True,
    n_jobs=1  # 避免并行处理导致的编码问题
)
```

### 评估指标

为全面评估各算法性能，我们采用了以下指标：

| 指标 | 说明 | 计算方法 | 适用场景 |
|------|------|----------|----------|
| **准确率 (Accuracy)** | 正确预测结果在所有预测中的比例 | (TP+TN)/(TP+TN+FP+FN) | 各类别样本数量平衡的分类问题 |
| **精确率 (Precision)** | 在预测为正类的结果中，真正为正类的比例 | TP/(TP+FP) | 需要降低假阳性的场景（如垃圾邮件检测） |
| **召回率 (Recall)** | 在所有真实正类中，被正确预测为正类的比例 | TP/(TP+FN) | 需要降低假阴性的场景（如疾病诊断） |
| **F1分数 (F1 Score)** | 精确率和召回率的调和平均 | 2×(精确率×召回率)/(精确率+召回率) | 需要平衡精确率和召回率的场景 |
| **ROC曲线下面积 (AUC)** | 评估模型区分不同类别能力的指标 | ROC曲线下的面积 | 评估模型的概率预测能力 |
| **训练时间** | 算法训练所需的时间（秒） | 直接计时 | 评估算法的计算复杂度和效率 |

*注：TP=真阳性, TN=真阴性, FP=假阳性, FN=假阴性*

## 代码实现说明

### 1. 数据加载与检查

程序首先尝试加载预处理后的数据，如果找不到则从原始数据加载：

```python
# 检查并加载预处理后的数据
X, y, class_names = check_and_load_processed_data()
```

### 2. 分类器训练与评估

使用多种分类器对数据进行训练和评估：

```python
# 训练并评估分类器
results, cv_results = train_classifiers(X, y, cv=5)
```

### 3. 结果可视化

分类结果通过多种图表进行可视化：

```python
# 可视化结果比较
visualize_results(results)
```

### 4. 最佳分类器分析

选择性能最佳的分类器进行详细分析：

```python
# 寻找表现最好的分类器
best_classifier = max(results.items(), key=lambda x: x[1]['accuracy'])[0]

# 对最佳分类器进行详细分析
best_report = analyze_best_classifier(X, y, best_classifier)
```

## 实验结果与分析

### 模型性能比较表

下表展示了各个分类器在鸢尾花数据集上的性能对比：

| 分类器 | 准确率 (%) | 精确率 (%) | 召回率 (%) | F1分数 (%) | ROC AUC | 训练时间 (秒) |
|--------|------------|------------|------------|------------|---------|---------------|
| 逻辑回归 | 96.00 ± 2.49 | 96.28 | 95.94 | 95.89 | 0.9987 | 0.075 |
| SVM | **96.67 ± 2.11** | **96.88** | **96.60** | **96.62** | 0.9981 | 0.064 |
| 决策树 | 95.33 ± 2.67 | 95.81 | 95.38 | 95.30 | 0.9652 | **0.048** |
| 随机森林 | 96.00 ± 2.49 | 96.28 | 95.94 | 95.89 | 0.9974 | 0.490 |
| K近邻 | 96.00 ± 3.27 | 96.33 | 95.94 | 95.99 | 0.9964 | 0.074 |

*注：表中的最佳值以**粗体**标出*

实验结果显示，支持向量机（SVM）在鸢尾花分类任务中表现最佳，具有最高的准确率（约96.67%）和其他评估指标。详细结果可在以下图表中查看：

- `classification_results.png` - 各分类器性能对比柱状图
- `classification_heatmap.png` - 各分类器各项指标热图
- `best_classifier_confusion_matrix.png` - 最佳分类器的混淆矩阵

### 数据可视化分析

为了更好地理解鸢尾花数据集的结构和分类效果，以下是几种重要的可视化图：

#### 特征成对关系散点图

下图展示了鸢尾花数据集中各特征之间的关系，不同颜色代表不同的鸢尾花品种：

![鸢尾花特征关系散点图](https://typora-oss-picgo.oss-cn-beijing.aliyuncs.com/202505181507796.png)

可以看出，花瓣长度和花瓣宽度是区分三种鸢尾花品种的最有效特征，特别是山鸢尾(Iris-setosa)与其他两种品种的区分非常明显。

#### PCA降维后的数据分布

通过主成分分析(PCA)将4维特征空间降至2维后的数据分布：

![PCA降维可视化](https://typora-oss-picgo.oss-cn-beijing.aliyuncs.com/202505181507797.png)

从图中可见，通过前两个主成分，已经能够很好地分离三种鸢尾花品种，特别是山鸢尾与其他两种品种的区分度非常高。

### 最佳模型详细性能（SVM）

| 类别 | 精确率 (%) | 召回率 (%) | F1分数 (%) |
|------|------------|------------|------------|
| Iris-setosa | 100.00 | 100.00 | 100.00 |
| Iris-versicolor | 100.00 | 100.00 | 100.00 |
| Iris-virginica | 100.00 | 100.00 | 100.00 |

SVM算法之所以表现出色，可能是因为：
1. 鸢尾花数据集的类别边界相对清晰
2. SVM在处理中小规模数据集时效果较好
3. 非线性核函数能够捕捉特征间的复杂关系

## 运行方法

确保已安装所需的Python库后，在终端中执行：

```
python iris_classification.py
```

程序将自动加载预处理后的数据（如果存在），或从原始数据开始处理，然后进行分类实验并生成结果。

## 结论

通过本实验，我们成功比较了多种分类算法在鸢尾花数据集上的性能，并发现SVM算法最适合此分类任务。本实验也展示了机器学习中常用的模型评估方法和可视化技术，为更复杂的分类问题提供了参考框架。 